{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XP1SqwYj8apv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "990dc48c-b755-4964-fde7-ac75789c92e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numerapi\n",
            "  Downloading numerapi-2.19.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from numerapi) (2.32.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from numerapi) (2024.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from numerapi) (2.9.0.post0)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.10/dist-packages (from numerapi) (4.66.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from numerapi) (8.1.7)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from numerapi) (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->numerapi) (1.26.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->numerapi) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->numerapi) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (2024.7.4)\n",
            "Downloading numerapi-2.19.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: numerapi\n",
            "Successfully installed numerapi-2.19.1\n",
            "Collecting numerai-tools\n",
            "  Downloading numerai_tools-0.1.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting pandas<=2.1.3,>=1.3.1 (from numerai-tools)\n",
            "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy~=1.26.2 in /usr/local/lib/python3.10/dist-packages (from numerai-tools) (1.26.4)\n",
            "Collecting scipy~=1.11.4 (from numerai-tools)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from numerai-tools) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<=2.1.3,>=1.3.1->numerai-tools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=2.1.3,>=1.3.1->numerai-tools) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=2.1.3,>=1.3.1->numerai-tools) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->numerai-tools) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->numerai-tools) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<=2.1.3,>=1.3.1->numerai-tools) (1.16.0)\n",
            "Downloading numerai_tools-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, pandas, numerai-tools\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numerai-tools-0.1.1 pandas-2.1.3 scipy-1.11.4\n",
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n",
            "Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightgbm\n",
            "Successfully installed lightgbm-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numerapi\n",
        "!pip install numerai-tools\n",
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numerapi import NumerAPI\n",
        "from numerai_tools.scoring import numerai_corr, correlation_contribution\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "api = NumerAPI()"
      ],
      "metadata": {
        "id": "95o9af9XDkXs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download v5.0 data"
      ],
      "metadata": {
        "id": "AHfPr4DkEZ8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VERSION = 5.0\n",
        "datasets = [dataset for dataset in api.list_datasets() if (dataset.startswith(f'v{VERSION}')) & ~(\"example\" in dataset)]\n",
        "datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExYwSMivEdPy",
        "outputId": "5f2ae22a-6d89-4d8b-a2d6-6b9b5139fe51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['v5.0/features.json',\n",
              " 'v5.0/train.parquet',\n",
              " 'v5.0/train_benchmark_models.parquet',\n",
              " 'v5.0/validation.parquet',\n",
              " 'v5.0/validation_benchmark_models.parquet']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for dataset in datasets:\n",
        "  api.download_dataset(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzFz5uESFdLT",
        "outputId": "2c9c805c-5d05-4c02-d7c3-a95dc46ed297"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "v5.0/features.json: 480kB [00:00, 2.40MB/s]                          \n",
            "v5.0/train.parquet: 2.37GB [01:37, 24.2MB/s]                            \n",
            "v5.0/train_benchmark_models.parquet: 81.7MB [00:03, 23.6MB/s]                            \n",
            "v5.0/validation.parquet: 3.18GB [02:15, 23.5MB/s]                            \n",
            "v5.0/validation_benchmark_models.parquet: 133MB [00:04, 28.9MB/s]                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 51.1 s, sys: 10.9 s, total: 1min 2s\n",
            "Wall time: 4min 6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "WZaSKEFOLvTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_metadata = json.load(open(\"v5.0/features.json\"))\n",
        "for f_set in feature_metadata[\"feature_sets\"]:\n",
        "  print(f\"{f_set} : {len(feature_metadata['feature_sets'][f_set])}\")"
      ],
      "metadata": {
        "id": "E4VqjyhgldAZ",
        "outputId": "b24eda6e-ea43-4727-f8ec-5f881adcb276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small : 42\n",
            "medium : 705\n",
            "all : 2376\n",
            "v2_equivalent_features : 304\n",
            "v3_equivalent_features : 1000\n",
            "fncv3_features : 400\n",
            "intelligence : 35\n",
            "charisma : 290\n",
            "strength : 135\n",
            "dexterity : 51\n",
            "constitution : 335\n",
            "wisdom : 140\n",
            "agility : 145\n",
            "serenity : 95\n",
            "sunshine : 325\n",
            "rain : 666\n",
            "midnight : 244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_set = feature_metadata[\"feature_sets\"][\"medium\"]"
      ],
      "metadata": {
        "id": "ZVTjPSN0mGqC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train = pd.read_parquet(\"v5.0/train.parquet\", columns=[\"era\", \"target\"] + feature_set)\n",
        "train.era = train.era.astype(int)\n",
        "# downsample to non-overlapping eras for d20 targets\n",
        "train = train[train[\"era\"].isin(train[\"era\"].unique()[::4])]\n",
        "\n",
        "validation = pd.read_parquet(\"v5.0/validation.parquet\", columns=[\"era\", \"target\", \"data_type\"] + feature_set)\n",
        "validation.era = validation.era.astype(int)\n",
        "validation = validation.loc[validation[\"data_type\"]==\"validation\"]\n",
        "validation.drop(\"data_type\", axis=1, inplace=True)\n",
        "# downsample to non-overlapping eras for d20 targets\n",
        "validation = validation[validation[\"era\"].isin(validation[\"era\"].unique()[::4])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyrgkZgk2IIl",
        "outputId": "cd521d32-44d3-4651-e518-32a275a33fd5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 52 s, sys: 42.8 s, total: 1min 34s\n",
            "Wall time: 10.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model"
      ],
      "metadata": {
        "id": "lp9dXL67nCqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = lgb.LGBMRegressor(\n",
        "  verbose=0,\n",
        "  n_estimators=2000,\n",
        "  learning_rate=0.01,\n",
        "  max_depth=5,\n",
        "  num_leaves=2**5-1,\n",
        "  colsample_bytree=0.1\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "  train[feature_set],\n",
        "  train[\"target\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "Y0LOBYLY297e",
        "outputId": "9cbe6af5-e524-4950-bf80-ce31565a567b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009490 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3525\n",
            "[LightGBM] [Info] Number of data points in the train set: 688184, number of used features: 705\n",
            "[LightGBM] [Info] Start training from score 0.500008\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(colsample_bytree=0.1, learning_rate=0.01, max_depth=5,\n",
              "              n_estimators=2000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.1, learning_rate=0.01, max_depth=5,\n",
              "              n_estimators=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.1, learning_rate=0.01, max_depth=5,\n",
              "              n_estimators=2000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate on validation set"
      ],
      "metadata": {
        "id": "95Yfp7tMqB_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_train_era = int(train[\"era\"].unique()[-1])\n",
        "eras_to_embargo = [era for era in [last_train_era + i for i in range(4)]]\n",
        "validation = validation[~validation[\"era\"].isin(eras_to_embargo)]\n",
        "\n",
        "validation[\"prediction\"] = model.predict(validation[feature_set])\n",
        "\n",
        "per_era_corr = validation.groupby(\"era\").apply(lambda x: numerai_corr(x[[\"prediction\"]].dropna(), x[\"target\"].dropna()))\n",
        "\n",
        "# Compute performance metrics\n",
        "corr_mean = per_era_corr.mean()\n",
        "corr_std = per_era_corr.std(ddof=0)\n",
        "corr_sharpe = corr_mean / corr_std\n",
        "corr_max_drawdown = (per_era_corr.cumsum().expanding(min_periods=1).max() - per_era_corr.cumsum()).max()\n",
        "\n",
        "print(\"corr_mean\", corr_mean.values[0])\n",
        "print(\"corr_std\", corr_std.values[0])\n",
        "print(\"corr_sharpe\", corr_sharpe.values[0])\n",
        "print(\"corr_max_drawdown\", corr_max_drawdown.values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzvTtb9k2cDd",
        "outputId": "f31301cb-0301-4aac-e4f9-434e940f8d96"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corr_mean 0.029137114270566877\n",
            "corr_std 0.022011423499522283\n",
            "corr_sharpe 1.3237269398409985\n",
            "corr_max_drawdown 0.03289748589129271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate in train set"
      ],
      "metadata": {
        "id": "WlRQz0KbqGBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"prediction\"] = model.predict(train[feature_set])\n",
        "\n",
        "per_era_corr = train.groupby(\"era\").apply(lambda x: numerai_corr(x[[\"prediction\"]].dropna(), x[\"target\"].dropna()))\n",
        "\n",
        "# Compute performance metrics\n",
        "corr_mean = per_era_corr.mean()\n",
        "corr_std = per_era_corr.std(ddof=0)\n",
        "corr_sharpe = corr_mean / corr_std\n",
        "corr_max_drawdown = (per_era_corr.cumsum().expanding(min_periods=1).max() - per_era_corr.cumsum()).max()\n",
        "\n",
        "print(\"corr_mean\", corr_mean.values[0])\n",
        "print(\"corr_std\", corr_std.values[0])\n",
        "print(\"corr_sharpe\", corr_sharpe.values[0])\n",
        "print(\"corr_max_drawdown\", corr_max_drawdown.values[0])"
      ],
      "metadata": {
        "id": "5Kgvl5typM6W",
        "outputId": "0bed6817-0578-4815-e606-2a69148cdef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corr_mean 0.19771191462764168\n",
            "corr_std 0.02391363333973824\n",
            "corr_sharpe 8.267748853500061\n",
            "corr_max_drawdown 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarks"
      ],
      "metadata": {
        "id": "rjQQ8-ECqtYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`'v5_lgbm_cyrusd20', 'v5_lgbm_teager2b20', 'v5_lgbm_ct_blend'`"
      ],
      "metadata": {
        "id": "FqmkudNIsSF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_benchmarks = pd.read_parquet(\"v5.0/validation_benchmark_models.parquet\")\n",
        "validation_benchmarks.era = validation_benchmarks.era.astype(int)\n",
        "# downsample to non-overlapping eras for d20 targets\n",
        "validation_benchmarks = validation_benchmarks[validation_benchmarks[\"era\"].isin(validation_benchmarks[\"era\"].unique()[::4])]\n",
        "validation_benchmarks = validation_benchmarks[validation_benchmarks[\"era\"] >= min(validation[\"era\"])]\n",
        "validation_benchmarks = pd.merge(validation_benchmarks, validation[\"target\"], left_index=True, right_index=True)\n",
        "\n",
        "per_era_corr = validation_benchmarks.groupby(\"era\").apply(lambda x: numerai_corr(x[[\"v5_lgbm_ct_blend\"]].dropna(), x[\"target\"].dropna()))\n",
        "\n",
        "# Compute performance metrics\n",
        "corr_mean = per_era_corr.mean()\n",
        "corr_std = per_era_corr.std(ddof=0)\n",
        "corr_sharpe = corr_mean / corr_std\n",
        "corr_max_drawdown = (per_era_corr.cumsum().expanding(min_periods=1).max() - per_era_corr.cumsum()).max()\n",
        "\n",
        "print(\"corr_mean\", corr_mean.values[0])\n",
        "print(\"corr_std\", corr_std.values[0])\n",
        "print(\"corr_sharpe\", corr_sharpe.values[0])\n",
        "print(\"corr_max_drawdown\", corr_max_drawdown.values[0])"
      ],
      "metadata": {
        "id": "zvKpaCOYqx71",
        "outputId": "f8ad3bcb-4082-45a7-d0e3-4a2d8535d404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corr_mean 0.03871170866170404\n",
            "corr_std 0.018508641528601124\n",
            "corr_sharpe 2.0915478103502854\n",
            "corr_max_drawdown 0.016409717532600787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pickle the model"
      ],
      "metadata": {
        "id": "HZO4CK7Bs6X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cloudpickle\n",
        "\n",
        "def predict(live_features: pd.DataFrame) -> pd.DataFrame:\n",
        "  live_predictions = model.predict(live_features[feature_set])\n",
        "  submission = pd.Series(live_predictions, index=live_features.index)\n",
        "  return submission.to_frame(\"prediction\")\n",
        "\n",
        "p = cloudpickle.dumps(predict)\n",
        "with open(\"predict.pkl\", \"wb\") as f:\n",
        "    f.write(p)"
      ],
      "metadata": {
        "id": "9AtzzhYKs8K5"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}